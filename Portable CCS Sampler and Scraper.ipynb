{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for scraping CCS data information from TADA site as well as Creating Interactive Sampling Map\n",
    "\n",
    "`\n",
    "By Oscar Lares for the Smart Mobility and Infrastructure Lab - 3/19/2024\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for scraping and reading CSV files\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining CCS names from CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to your PATHS!\n",
    "ccs_portables_path = r\"F:\\Data\\CCS\\Portable CCS Station Data\" #path to portables CCS station data main folder\n",
    "ccs_permanent_path = r\"F:\\Data\\CCS\\Permanent CCS Station Data\\Lane Exports\" #path to permanent CCS station data main folder\n",
    "\n",
    "#define column name so that you dont need to read in all columns from the CSV\n",
    "column_names = ['Site','Volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get CCS names from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_CCS_sites(path=r\"F:\\Data\\CCS\\Portable CCS Station Data\", column_names=column_names):\n",
    "\n",
    "    #init list to store unique site names\n",
    "    unique_site_values = set()\n",
    "\n",
    "    #loop through each folder year in the main path given\n",
    "    for year in os.listdir(path):\n",
    "        print('--------------------------')\n",
    "        print(f'Getting data from {year}')\n",
    "        print('--------------------------')\n",
    "        year_path = os.path.join(path, year)\n",
    "\n",
    "        #check if its a directory\n",
    "        if os.path.isdir(year_path):\n",
    "\n",
    "            #Now use glob to iterate through all the folders in the sub directory containing data for that year\n",
    "            csv_files = glob.glob(os.path.join(year_path, '*.csv'))\n",
    "\n",
    "            #now iterate through each CSV file since we have a list of filenames\n",
    "            for csv_file in csv_files:\n",
    "                print(f'Getting site values from file {csv_file}. . .')\n",
    "\n",
    "                #read into pandas\n",
    "                df = pd.read_csv(csv_file, usecols = column_names)\n",
    "\n",
    "                #eliminate any rows where 'Volume' is NaN\n",
    "                df = df.dropna(subset=['Volume'])\n",
    "\n",
    "                #get unique values from df\n",
    "                current_sites_from_df = set(df['Site'].unique())\n",
    "\n",
    "                #add only new sites to the set of all unique sites\n",
    "                unique_site_values.update(current_sites_from_df)\n",
    "\n",
    "    #once loop is done running, convert the set to a list to obtain final list of all CCS sites present in CSV files\n",
    "    unique_site_values_list = list(unique_site_values)\n",
    "    print('##############################')\n",
    "    print('All done!')\n",
    "\n",
    "    return unique_site_values_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCS Portables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Getting data from 2021\n",
      "--------------------------\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-12.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-01.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-02.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-03.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-04.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-05.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-06.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-07.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-08.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-09.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-10.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2021\\2021-11.csv. . .\n",
      "--------------------------\n",
      "Getting data from 2022\n",
      "--------------------------\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-01.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-02.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-03.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-04.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-05.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-06.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-07.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-08.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-09.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-10.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-11.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2022\\2022-12.csv. . .\n",
      "--------------------------\n",
      "Getting data from 2023\n",
      "--------------------------\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-02.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-03.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-04.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-05.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-06.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-07.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-08.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-09.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-10.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-11.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-12.csv. . .\n",
      "Getting site values from file F:\\Data\\CCS\\Portable CCS Station Data\\2023\\2023-01.csv. . .\n",
      "##############################\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "CCS_portables_list = get_unique_CCS_sites(path=ccs_portables_path, column_names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCS Permanents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCS_permanent_list = get_unique_CCS_sites(path=ccs_permanent_path, column_names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping CCS from TADA site (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(site_id, site_type):\n",
    "    base_url = \"https://gdottrafficdata.drakewell.com/sitedashboard.asp?\"\n",
    "    \n",
    "    # Remove the dash\n",
    "    clean_site_id = site_id.replace('-', '')\n",
    "    \n",
    "    if site_type == \"PORTABLES\":\n",
    "        # Insert the underscore before the last 4 digits, then pad with leading zeroes\n",
    "        cosit_formatted = clean_site_id[:-4] + \"_\" + clean_site_id[-4:]\n",
    "        cosit_formatted = cosit_formatted.zfill(12)  # 12 digits (including underscore)\n",
    "        node_value = \"GDOT_PORTABLES\"\n",
    "\n",
    "    elif site_type == \"CCS\":\n",
    "        # Pad with leading zeroes to make the total length 12\n",
    "        cosit_formatted = clean_site_id.zfill(12)\n",
    "        node_value = \"GDOT_CCS\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid site type. Must be 'PORTABLES' or 'CCS'.\")\n",
    "\n",
    "    url = f\"{base_url}node={node_value}&cosit={cosit_formatted}\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test usage:\n",
    "portables_url = generate_url(\"139-0183\", \"CCS\")\n",
    "ccs_url = generate_url(\"097-r807\", \"PORTABLES\")\n",
    "\n",
    "print(portables_url)\n",
    "print(ccs_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site scraping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_sites(sites, site_type, webdriver_path, save_interval=100, output_file='scraped_data.csv'):\n",
    "\n",
    "    errors = []\n",
    "    service = Service(executable_path=webdriver_path)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"user-agent=Chrome/88.0.4324.150\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    data_list = [] #list to store site data dicts\n",
    "\n",
    "    for i, site_id in enumerate(sites):\n",
    "        try:\n",
    "            # Generate the URL based on the site_id and site_type\n",
    "            url = generate_url(site_id, site_type)  # generate url from function\n",
    "            print(url)\n",
    "            driver.get(url)\n",
    "\n",
    "            # Scraping\n",
    "            # lrs_element = WebDriverWait(driver, 10).until(\n",
    "            #     EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'LRS section:')]/following-sibling::span\"))\n",
    "            # ).text\n",
    "\n",
    "            # city_element = WebDriverWait(driver, 10).until(\n",
    "            #     EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'City:')]/following-sibling::span\"))\n",
    "            # ).text    \n",
    "\n",
    "            county_element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'County:')]/following-sibling::span\"))\n",
    "            ).text\n",
    "\n",
    "            functional_class_element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'Functional class:')]/following-sibling::span\"))\n",
    "            ).text\n",
    "\n",
    "            coordinates_element = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'Coordinates:')]/following-sibling::span\"))\n",
    "                ).text\n",
    "\n",
    "            # add scraped data to dict\n",
    "            data_row = {                \n",
    "                'Site ID': site_id,\n",
    "                'County': county_element,\n",
    "                'Functional Class': functional_class_element,\n",
    "                'Coordinates': coordinates_element\n",
    "                }\n",
    "             #append current dict of data to the data list\n",
    "            data_list.append(data_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping site {site_id}: {e}\")\n",
    "            errors.append({'Site ID': site_id, 'Error': str(e)})\n",
    "\n",
    "        finally:\n",
    "            # Periodic save of both data and errors\n",
    "            if i % save_interval == 0 or i == len(sites) - 1:\n",
    "                checkpoint_df = pd.DataFrame(data_list)\n",
    "                checkpoint_df.to_csv(f'{output_file}_partial.csv', index=False)\n",
    "                # Save the error list as well\n",
    "                pd.DataFrame(errors).to_csv(f'error_sites_{site_type}.csv', index=False)\n",
    "                print(f\"Progress and errors saved at site {i}.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert final list to DataFrame and save\n",
    "    final_df = pd.DataFrame(data_list)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(\"Final data saved.\")\n",
    "\n",
    "    # Save the final error list\n",
    "    pd.DataFrame(errors).to_csv(f'error_sites_{site_type}_final.csv', index=False)\n",
    "    print(f\"Final list of errors saved. Check 'error_sites_{site_type}_final.csv'.\")\n",
    "\n",
    "    return final_df, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = r\"C:\\Program Files\\Webdrivers\\chromedriver-win64\\chromedriver.exe\"\n",
    "save_interval = 100\n",
    "permanent_sites_output_filename = 'CCS_permanent_sites_information.csv'\n",
    "portable_sites_output_filename = 'CCS_portable_sites_information.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permanent CCS site scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, error_sites = scrape_sites(CCS_permanent_list, 'CCS', chromedriver_path, save_interval=save_interval, output_file=permanent_sites_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portable CCS site scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_portables_df, portables_error_sites = scrape_sites(CCS_portables_list, 'PORTABLES', chromedriver_path, save_interval=save_interval, output_file=portable_sites_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data and Create Interactive Map for Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_duration(duration_str):\n",
    "    parts = duration_str.strip().split()\n",
    "\n",
    "    #Assuming format is in the form \"X hours Y minutes\"\n",
    "    total_minutes = 0\n",
    "\n",
    "    if 'hour' in duration_str:\n",
    "        total_minutes += int(parts[0]) * 60 #converting the hour to minutes\n",
    "        total_minutes += int(parts[2]) if 'minute' in duration_str else 0\n",
    "    \n",
    "    else:\n",
    "        total_minutes += int(parts[0])\n",
    "    return total_minutes\n",
    "\n",
    "# Function to read and preprocess and match RITIS events to CCS sites\n",
    "def match_ritis_events(events_gdf, ccs_gdf, radius=1600, predicate='within'):\n",
    "    geoevents = events_gdf[['geometry']]\n",
    "    geosites = ccs_gdf[['geometry', 'TC_NUM']]\n",
    "\n",
    "    # Convert the CRS to a projected CRS for distance calculations\n",
    "    geoevents = geoevents.to_crs('EPSG:3857')\n",
    "    geosites = geosites.to_crs('EPSG:3857')\n",
    "\n",
    "    print('CRS for events:', events_gdf.crs)\n",
    "    print('CRS for sites:', ccs_gdf.crs)\n",
    "    \n",
    "    buffered_sites = geosites.geometry.buffer(radius)\n",
    "    buffered_sites = gpd.GeoDataFrame(geometry=buffered_sites, crs='EPSG:3857') #convert back to geodf \n",
    "\n",
    "    # Perform spatial join to find crashes within the buffered sites\n",
    "    events_in_radius = gpd.sjoin(geoevents, buffered_sites, predicate=predicate)\n",
    "\n",
    "    # Use this index to map back to the 'TC_NUM' or the site identifier\n",
    "    events_in_radius['CCS_Pair'] = events_in_radius['index_right'].map(geosites['TC_NUM'])\n",
    "\n",
    "    # Drop the 'index_right' as it's no longer needed\n",
    "    events_in_radius = events_in_radius.drop(columns=['index_right'])\n",
    "\n",
    "    # Convert back to the original CRS\n",
    "    events_in_radius = events_in_radius.to_crs('EPSG:4326')\n",
    "\n",
    "    # Merge 'CCS_Pair' information back into the original events_gdf using the index\n",
    "    events_gdf = events_gdf.merge(events_in_radius[['CCS_Pair']], left_index=True, right_index=True, how='left')\n",
    "    events_gdf = events_gdf.dropna(subset=['CCS_Pair'])\n",
    "    print('Size of events_gdf with CCS_Pair: ', events_gdf.shape)\n",
    "\n",
    "    return events_gdf\n",
    "\n",
    "def filter_events_to_counties(ritis_file_path, shp_path):\n",
    "\n",
    "    events_within_counties_chunks = []\n",
    "    counties = gpd.read_file(shp_path)\n",
    "\n",
    "    #load events data\n",
    "    for year in os.listdir(ritis_file_path):\n",
    "        print('--------------------------')\n",
    "        print(f'Getting data from {year}')\n",
    "        print('--------------------------')\n",
    "        year_path = os.path.join(ritis_file_path, year)\n",
    "\n",
    "        csv_files = glob.glob(os.path.join(year_path, '*.csv'))\n",
    "\n",
    "        for file in csv_files:\n",
    "            print(f'Getting event data from file {file}. . .')\n",
    "            events_df = pd.read_csv(file)\n",
    "            events_df = events_df[(events_df['Agency-specific Type'] == 'Accident') | (events_df['Agency-specific Type'] == 'Fire') | (events_df['Agency-specific Type'] == 'Debris')]\n",
    "            events_df['Duration_minutes'] = events_df['Duration (Incident clearance time)'].apply(parse_duration)\n",
    "            events_df = events_df[events_df['Duration_minutes'] > 20]\n",
    "\n",
    "            events_gdf = gpd.GeoDataFrame(events_df, geometry=gpd.points_from_xy(events_df.Longitude, events_df.Latitude))\n",
    "            events_gdf.crs = counties.crs\n",
    "\n",
    "            events_filtered = gpd.sjoin(events_gdf, counties, how='inner', predicate='within')\n",
    "            events_filtered.drop(['index_right'], axis=1, inplace=True)\n",
    "\n",
    "            events_within_counties_chunks.append(events_filtered)\n",
    "\n",
    "            print(f'Event data for file {file[-11:]} appended')\n",
    "\n",
    "    events_within_counties = pd.concat(events_within_counties_chunks)\n",
    "\n",
    "    return events_within_counties\n",
    "\n",
    "def filter_sites_to_counties(filtered_sites, shp_path):\n",
    "\n",
    "    counties = gpd.read_file(shp_path)\n",
    "    filtered_sites_gdf = gpd.GeoDataFrame(filtered_sites, geometry=gpd.points_from_xy(filtered_sites.LONG, filtered_sites.LAT))\n",
    "\n",
    "    filtered_sites_gdf.crs = counties.crs\n",
    "\n",
    "    sites_within_counties = gpd.sjoin(filtered_sites_gdf, counties, how='inner', predicate='within')\n",
    "    sites_within_counties.drop(['index_right'], axis=1, inplace=True)\n",
    "\n",
    "    return sites_within_counties\n",
    "\n",
    "def calculate_distances(joined_gdf, ccs_gdf):\n",
    "    # Create an empty DataFrame to store the closest CCS site and distance for each event\n",
    "    closest_sites_info = pd.DataFrame(columns=['EventID', 'ClosestCCS', 'Distance'])\n",
    "\n",
    "    # Group by the event's original index to handle potential multiple matches\n",
    "    grouped = joined_gdf.groupby(joined_gdf.index)\n",
    "\n",
    "    for event_id, matches in grouped:\n",
    "        # Calculate the distance from the event to each CCS site in the matches\n",
    "        distances = matches.apply(lambda match: ccs_gdf.loc[match['index_right']].geometry.distance(match['geometry']), axis=1)\n",
    "        # Get the index of the closest CCS site\n",
    "        closest_site_idx = distances.idxmin()\n",
    "        # Get the ID of the closest CCS site\n",
    "        closest_ccs_id = matches.loc[closest_site_idx]['index_right']\n",
    "        # Get the minimum distance\n",
    "        min_distance = distances.min()\n",
    "        # Append to the DataFrame\n",
    "        closest_sites_info = closest_sites_info.append({\n",
    "            'EventID': event_id,\n",
    "            'ClosestCCS': closest_ccs_id,\n",
    "            'Distance': min_distance\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return closest_sites_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter CCS sites and RITIS events to only cover in south GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define RITIS event path and Shape file path for counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ritis_events_path = r'F:\\Data\\RITIS Event Data'\n",
    "shp_path = r'D:\\OneDrive - University of Georgia\\Research\\Fall 2023\\RP 23-25 - Probe Project\\SHP files\\Counties_Georgia.shp'\n",
    "site_locations_path = r\"F:\\Data\\CCS\\Site Locations 2023.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read in site location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_locations = pd.read_excel(site_locations_path, sheet_name='Short-term')\n",
    "# site_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter down site locations to only include sites we have data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sites = site_locations[site_locations['TC_NUM'].isin(CCS_portables_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all events falling within South GA counties we want to look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Getting data from 2022\n",
      "--------------------------\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\01-2022.csv. . .\n",
      "Event data for file 01-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\02-2022.csv. . .\n",
      "Event data for file 02-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\03-2022.csv. . .\n",
      "Event data for file 03-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\04-2022.csv. . .\n",
      "Event data for file 04-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\05-2022.csv. . .\n",
      "Event data for file 05-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\06-2022.csv. . .\n",
      "Event data for file 06-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\07-2022.csv. . .\n",
      "Event data for file 07-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\08-2022.csv. . .\n",
      "Event data for file 08-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\10-2022.csv. . .\n",
      "Event data for file 10-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\11-2022.csv. . .\n",
      "Event data for file 11-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\09-2022.csv. . .\n",
      "Event data for file 09-2022.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2022\\12-2022.csv. . .\n",
      "Event data for file 12-2022.csv appended\n",
      "--------------------------\n",
      "Getting data from 2023\n",
      "--------------------------\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\01-2023.csv. . .\n",
      "Event data for file 01-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\02-2023.csv. . .\n",
      "Event data for file 02-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\03-2023.csv. . .\n",
      "Event data for file 03-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\04-2023.csv. . .\n",
      "Event data for file 04-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\05-2023.csv. . .\n",
      "Event data for file 05-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\06-2023.csv. . .\n",
      "Event data for file 06-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\07-2023.csv. . .\n",
      "Event data for file 07-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\08-2023.csv. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oscar\\AppData\\Local\\Temp\\ipykernel_13584\\3069651871.py:65: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  events_df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event data for file 08-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\09-2023.csv. . .\n",
      "Event data for file 09-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\10-2023.csv. . .\n",
      "Event data for file 10-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\11-2023.csv. . .\n",
      "Event data for file 11-2023.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2023\\12-2023.csv. . .\n",
      "Event data for file 12-2023.csv appended\n",
      "--------------------------\n",
      "Getting data from 2021\n",
      "--------------------------\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\04-2021.csv. . .\n",
      "Event data for file 04-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\05-2021.csv. . .\n",
      "Event data for file 05-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\06-2021.csv. . .\n",
      "Event data for file 06-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\07-2021.csv. . .\n",
      "Event data for file 07-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\08-2021.csv. . .\n",
      "Event data for file 08-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\09-2021.csv. . .\n",
      "Event data for file 09-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\10-2021.csv. . .\n",
      "Event data for file 10-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\11-2021.csv. . .\n",
      "Event data for file 11-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\12-2021.csv. . .\n",
      "Event data for file 12-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\03-2021.csv. . .\n",
      "Event data for file 03-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\02-2021.csv. . .\n",
      "Event data for file 02-2021.csv appended\n",
      "Getting event data from file F:\\Data\\RITIS Event Data\\2021\\01-2021.csv. . .\n",
      "Event data for file 01-2021.csv appended\n"
     ]
    }
   ],
   "source": [
    "events_within_counties = filter_events_to_counties(ritis_events_path, shp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all sites falling within South GA counties we want to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_within_counties = filter_sites_to_counties(filtered_sites, shp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match RITIS events to CCS sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS for events: EPSG:4326\n",
      "CRS for sites: EPSG:4326\n",
      "Size of events_gdf with CCS_Pair:  (117936, 42)\n"
     ]
    }
   ],
   "source": [
    "matched_events = match_ritis_events(events_within_counties, sites_within_counties, radius=500, predicate='within')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the event counts for each corresponding site and add it to the sites DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_count = matched_events.groupby('CCS_Pair').size().reset_index(name='event_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_within_counties_matched = pd.merge(sites_within_counties, event_count, left_on='TC_NUM', right_on='CCS_Pair', how='left').dropna(subset='event_count')\n",
    "sites_within_counties_matched['event_count'] = sites_within_counties_matched['event_count'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating interactive map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_bb06029ee4d7100dad3217d98a5c5c88 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.markercluster/1.1.0/leaflet.markercluster.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.markercluster/1.1.0/MarkerCluster.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.markercluster/1.1.0/MarkerCluster.Default.css&quot;/&gt;\n",
       "    &lt;script src=&quot;https://unpkg.com/leaflet.featuregroup.subgroup@1.0.2/dist/leaflet.featuregroup.subgroup.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet-groupedlayercontrol/0.6.1/leaflet.groupedlayercontrol.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet-groupedlayercontrol/0.6.1/leaflet.groupedlayercontrol.min.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_bb06029ee4d7100dad3217d98a5c5c88&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_bb06029ee4d7100dad3217d98a5c5c88 = L.map(\n",
       "                &quot;map_bb06029ee4d7100dad3217d98a5c5c88&quot;,\n",
       "                {\n",
       "                    center: [0.0, 0.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 6,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_6abb8758ef7292e5ccf1555a1ab9d01e = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_6abb8758ef7292e5ccf1555a1ab9d01e.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var feature_group_4b157211483bf17b40ce6af2044e9db9 = L.featureGroup(\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            feature_group_4b157211483bf17b40ce6af2044e9db9.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var tile_layer_ef80b8c55c8258562d394ead82800500 = L.tileLayer(\n",
       "                &quot;https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca href=\\&quot;https://carto.com/attributions\\&quot;\\u003eCARTO\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 20, &quot;maxZoom&quot;: 20, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abcd&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_ef80b8c55c8258562d394ead82800500.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var marker_cluster_b1a1c20bf640f4341b6dbc23ed36fe5a = L.markerClusterGroup(\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            marker_cluster_b1a1c20bf640f4341b6dbc23ed36fe5a.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var feature_group_sub_group_bce35bbc1d3a9461c3e11ff1ed5f3c64 = L.featureGroup.subGroup(\n",
       "                marker_cluster_b1a1c20bf640f4341b6dbc23ed36fe5a\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var marker_77ca1ac9984ed8aa4c14a7268bf25486 = L.marker(\n",
       "                [-1.0, -1.0],\n",
       "                {}\n",
       "            ).addTo(feature_group_sub_group_bce35bbc1d3a9461c3e11ff1ed5f3c64);\n",
       "        \n",
       "    \n",
       "            var marker_aa0737628f374816c1390dbd9bc51ee3 = L.marker(\n",
       "                [1.0, 1.0],\n",
       "                {}\n",
       "            ).addTo(feature_group_sub_group_bce35bbc1d3a9461c3e11ff1ed5f3c64);\n",
       "        \n",
       "    \n",
       "            feature_group_sub_group_bce35bbc1d3a9461c3e11ff1ed5f3c64.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var feature_group_sub_group_7d95a1b2635fc16301221f7465ff50b8 = L.featureGroup.subGroup(\n",
       "                marker_cluster_b1a1c20bf640f4341b6dbc23ed36fe5a\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var marker_d5e706aa23dd8795b3ce98805de86d34 = L.marker(\n",
       "                [-1.0, 1.0],\n",
       "                {}\n",
       "            ).addTo(feature_group_sub_group_7d95a1b2635fc16301221f7465ff50b8);\n",
       "        \n",
       "    \n",
       "            var marker_4e9ca1c9f86d95a930682665b2c200fe = L.marker(\n",
       "                [1.0, -1.0],\n",
       "                {}\n",
       "            ).addTo(feature_group_sub_group_7d95a1b2635fc16301221f7465ff50b8);\n",
       "        \n",
       "    \n",
       "            feature_group_sub_group_7d95a1b2635fc16301221f7465ff50b8.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var feature_group_sub_group_66eb5370338424f5002d913c976a9282 = L.featureGroup.subGroup(\n",
       "                marker_cluster_b1a1c20bf640f4341b6dbc23ed36fe5a\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var marker_734a3119e531727862762cda111d35e7 = L.marker(\n",
       "                [1.0, 2.0],\n",
       "                {}\n",
       "            ).addTo(feature_group_sub_group_66eb5370338424f5002d913c976a9282);\n",
       "        \n",
       "    \n",
       "            var marker_0e0b24ee6701eb919cb421b92b29b359 = L.marker(\n",
       "                [-1.0, -2.0],\n",
       "                {}\n",
       "            ).addTo(feature_group_sub_group_66eb5370338424f5002d913c976a9282);\n",
       "        \n",
       "    \n",
       "            feature_group_sub_group_66eb5370338424f5002d913c976a9282.addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "        \n",
       "    \n",
       "            var layer_control_cf87de6d3426d226207baecf53e43ee3_layers = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_6abb8758ef7292e5ccf1555a1ab9d01e,\n",
       "                    &quot;cartodbpositron&quot; : tile_layer_ef80b8c55c8258562d394ead82800500,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;poop&quot; : feature_group_4b157211483bf17b40ce6af2044e9db9,\n",
       "                },\n",
       "            };\n",
       "            let layer_control_cf87de6d3426d226207baecf53e43ee3 = L.control.layers(\n",
       "                layer_control_cf87de6d3426d226207baecf53e43ee3_layers.base_layers,\n",
       "                layer_control_cf87de6d3426d226207baecf53e43ee3_layers.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "\n",
       "        \n",
       "    \n",
       "\n",
       "            L.control.groupedLayers(\n",
       "                null,\n",
       "                {\n",
       "                    &quot;Events&quot; : {\n",
       "                        &quot;Less than 4 Events&quot; : feature_group_sub_group_bce35bbc1d3a9461c3e11ff1ed5f3c64,\n",
       "                        &quot;Fire&quot; : feature_group_sub_group_7d95a1b2635fc16301221f7465ff50b8,\n",
       "                        &quot;Accident&quot; : feature_group_sub_group_66eb5370338424f5002d913c976a9282,\n",
       "                    },\n",
       "                },\n",
       "                {&quot;collapsed&quot;: false},\n",
       "            ).addTo(map_bb06029ee4d7100dad3217d98a5c5c88);\n",
       "\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x20e868e6d50>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###test code for troubleshooting issues\n",
    "\n",
    "m = folium.Map(location=[0, 0], zoom_start=6)\n",
    "\n",
    "m.add_child(folium.FeatureGroup(name='test'))\n",
    "folium.TileLayer('CartoDB positron').add_to(m)\n",
    "\n",
    "mcg = folium.plugins.MarkerCluster(control=False, name='test2')\n",
    "m.add_child(mcg)\n",
    "\n",
    "g1 = folium.plugins.FeatureGroupSubGroup(mcg, \"Less than 4 Events\")\n",
    "g2 = folium.plugins.FeatureGroupSubGroup(mcg, \"Fire\")\n",
    "g3 = folium.plugins.FeatureGroupSubGroup(mcg, \"Accident\")\n",
    "\n",
    "test_dict = {'g1':g1, 'g2':g2, 'g3':g3}\n",
    "\n",
    "folium.Marker([-1, -1]).add_to(g1)\n",
    "folium.Marker([1, 1]).add_to(g1)\n",
    "\n",
    "folium.Marker([-1, 1]).add_to(g2)\n",
    "folium.Marker([1, -1]).add_to(g2)\n",
    "\n",
    "folium.Marker([1, 2]).add_to(g3)\n",
    "folium.Marker([-1, -2]).add_to(g3)\n",
    "\n",
    "for hehe, test_group in test_dict.items():\n",
    "    m.add_child(test_group)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "GroupedLayerControl(groups={'Events':[test_dict[test] for test in test_dict]}, exclusive_groups=False, collapsed=False).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster, GroupedLayerControl, FeatureGroupSubGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define style functions for coloring etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_function1(feature):\n",
    "    return {'fillColor':'light gray','color':'#000000', 'weight':'1'}\n",
    "\n",
    "def style_function2(feature):\n",
    "    return {'fillColor':'yellow','color':'gray', 'weight':'1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read in Georgia Shape file and South Georgia Shape Files to determine boundaries and geographic locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_shp = gpd.read_file('D:/OneDrive - University of Georgia/RP_22-35_Area-Specific_LDF/data/GA Map Data and Poly Files/US/tl_2020_us_state.shp')\n",
    "ga_geom = ga_shp[ga_shp['NAME'] == 'Georgia']['geometry'].iloc[0]\n",
    "\n",
    "south_georgia = gpd.read_file(shp_path)\n",
    "south_georgia = south_georgia[['geometry']]\n",
    "\n",
    "south_gajson = south_georgia.to_crs(epsg='4326').to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[sites_within_counties['LAT'].mean(), sites_within_counties['LONG'].mean()], zoom_start=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define feature groups and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA = folium.FeatureGroup(name='Georgia')\n",
    "southGA = folium.FeatureGroup(name='South Georgia')\n",
    "\n",
    "site_cluster = MarkerCluster(control=False)\n",
    "event_cluster = MarkerCluster(control=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define unique event types/agencies/durations in order to have customized layer control for interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_specific_types = {}\n",
    "\n",
    "specific_types = matched_events['Agency-specific Type'].unique()\n",
    "\n",
    "event_count_groups = {\n",
    "    'less_than_50': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Less than 50 events'),\n",
    "    'between_50_and_100': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 50-100 events'),\n",
    "    'between_101_and_200': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 101-200 events'),\n",
    "    'between_201_and_300': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 201-300 events'),\n",
    "    'between_301_and_400': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 301-400 events'),\n",
    "    'between_401_and_500': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 401-500 events'),\n",
    "    'between_501_and_600': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 501-600 events'),\n",
    "    'between_601_and_700': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 601-700 events'),\n",
    "    'between_701_and_800': folium.plugins.FeatureGroupSubGroup(site_cluster, 'Between 701-800 events'),\n",
    "    'more_than_801': folium.plugins.FeatureGroupSubGroup(site_cluster, 'More than 801 Events')\n",
    "}\n",
    "\n",
    "for specific_type in specific_types:\n",
    "    specific_type_key = f'{specific_type}'\n",
    "    event_specific_types[specific_type_key] = folium.plugins.FeatureGroupSubGroup(event_cluster, f'{specific_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, site in sites_within_counties_matched.iterrows():\n",
    "\n",
    "    site_id = site['TC_NUM']\n",
    "    county = site['Label']\n",
    "    no_lanes = site['TOTAL_LANE']\n",
    "    area = site['Urban_Rural']\n",
    "    f_class = site['F_SYSTEM']\n",
    "    events = site['event_count']\n",
    "\n",
    "    popup_content_site = f'<b>Site ID: {site_id}</b><br>Total Events Matched: {events}<br>County: {county}<br># of Lanes (total): {no_lanes}<br>Area: {area}<br>Facility Type (classification): {f_class}'\n",
    "\n",
    "    site_marker = folium.Marker([site['LAT'], site['LONG']], tooltip=f'Site {site_id}', icon=folium.Icon(icon='car', prefix='fa',color='black'), popup=popup_content_site)\n",
    "\n",
    "    site_popup = folium.Popup(popup_content_site, max_width=400)\n",
    "    site_marker.add_child(site_popup)\n",
    "\n",
    "    # Determine the correct event count group\n",
    "    if events < 50:\n",
    "        event_count_key = 'less_than_50'\n",
    "    elif 50 <= events <= 100:\n",
    "        event_count_key = 'between_50_and_100'\n",
    "    elif 101 <= events <= 200:\n",
    "        event_count_key = 'between_101_and_200'\n",
    "    elif 201 <= events <= 300:\n",
    "        event_count_key = 'between_201_and_300'\n",
    "    elif 301 <= events <= 400:\n",
    "        event_count_key = 'between_301_and_400'\n",
    "    elif 401 <= events <= 500:\n",
    "        event_count_key = 'between_401_and_500'\n",
    "    elif 501 <= events <= 600:\n",
    "        event_count_key = 'between_501_and_600'\n",
    "    elif 601 <= events <= 700:\n",
    "        event_count_key = 'between_601_and_700'\n",
    "    elif 701 <= events <= 800:\n",
    "        event_count_key = 'between_701_and_800'\n",
    "    else:\n",
    "        event_count_key = 'more_than_801'\n",
    "\n",
    "    site_marker.add_to(event_count_groups[event_count_key])\n",
    "\n",
    "for _, event in matched_events.iterrows():\n",
    "\n",
    "    identifier = event['Event ID']\n",
    "    type = event['Standardized Type']\n",
    "    specific_type = event['Agency-specific Type']\n",
    "    specific_subtype = event['Agency-specific Sub Type']\n",
    "    duration = event['Duration_minutes']\n",
    "    agency = event['Agency']\n",
    "    ccs = event['CCS_Pair']\n",
    "\n",
    "    popup_content_event = f'<b>Crash ID: {identifier}</b><br>Agency: {agency}<br>Type: {type}<br>Subtype: {specific_type}<br>Duration: {duration}<br>CCS station pair: {ccs}'\n",
    "\n",
    "    event_marker = folium.CircleMarker([event['Latitude'], event['Longitude']], radius=4, popup=popup_content_event, tooltip=f'Event {identifier}', color='red')\n",
    "    \n",
    "    # Determine the correct duration group\n",
    "    if duration < 30:\n",
    "        duration_key = 'less_than_30'\n",
    "    elif 30 <= duration <= 60:\n",
    "        duration_key = 'between_30_and_60'\n",
    "    else:\n",
    "        duration_key = 'more_than_60'\n",
    "\n",
    "    event_popup = folium.Popup(popup_content_event, max_width=400)\n",
    "    event_marker.add_child(event_popup)\n",
    "\n",
    "    event_marker.add_to(event_specific_types[specific_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add layer control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.plugins.groupedlayercontrol.GroupedLayerControl at 0x20e78615520>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folium.TileLayer('CartoDB positron').add_to(map)\n",
    "\n",
    "folium.GeoJson(ga_geom, style_function=style_function1).add_to(GA)\n",
    "folium.GeoJson(south_georgia, style_function=style_function2).add_to(southGA)\n",
    "\n",
    "GA.add_to(map)\n",
    "southGA.add_to(map)\n",
    "map.add_child(site_cluster)\n",
    "map.add_child(event_cluster)\n",
    "\n",
    "for event_type, subgroup in event_specific_types.items():\n",
    "    map.add_child(subgroup)\n",
    "\n",
    "for site, count_group in event_count_groups.items():\n",
    "    map.add_child(count_group)\n",
    "\n",
    "folium.LayerControl(collapsed=True).add_to(map)\n",
    "\n",
    "GroupedLayerControl(\n",
    "    groups={'Specific Event Types': [event_specific_types[specific_event] for specific_event in event_specific_types],\n",
    "            'Portable CCS Sites': [event_count_groups[event_count_group] for event_count_group in event_count_groups]\n",
    "            },\n",
    "    collapsed=False,\n",
    "    exclusive_groups=False\n",
    "    ).add_to(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.save(r'D:\\OneDrive - University of Georgia\\Research\\Fall 2023\\RP 23-25 - Probe Project\\Probe Sites Interactive Map.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RP23-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
